{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel, BertTokenizer\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_df = pd.read_csv(\"recipes_with_final_embeddings.csv\")\n",
    "embeddings = recipes_df['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_category(categories1, categories2):\n",
    "    set1 = set(eval(categories1)) if isinstance(categories1, str) else set(categories1)\n",
    "    set2 = set(eval(categories2)) if isinstance(categories2, str) else set(categories2)\n",
    "    return len(set1.intersection(set2)) > 0\n",
    "\n",
    "def generate_pairs(recipes_df, embeddings, num_pairs=1000):\n",
    "    positive_pairs, negative_pairs = [], []\n",
    "    \n",
    "    for _ in range(num_pairs):\n",
    "        idx1 = np.random.randint(len(recipes_df))\n",
    "        \n",
    "        positive_candidates = [idx for idx in recipes_df.index if idx != idx1 and common_category(\n",
    "            recipes_df.iloc[idx1]['categories'], recipes_df.iloc[idx]['categories'])]\n",
    "        \n",
    "        if positive_candidates:\n",
    "            idx2 = np.random.choice(positive_candidates)\n",
    "            positive_pairs.append([embeddings[idx1], embeddings[idx2]])\n",
    "\n",
    "        negative_candidates = [idx for idx in recipes_df.index if idx != idx1 and not common_category(\n",
    "            recipes_df.iloc[idx1]['categories'], recipes_df.iloc[idx]['categories'])]\n",
    "        \n",
    "        if negative_candidates:\n",
    "            idx3 = np.random.choice(negative_candidates)\n",
    "            negative_pairs.append([embeddings[idx1], embeddings[idx3]])\n",
    "\n",
    "    return np.array(positive_pairs), np.array(negative_pairs)\n",
    "\n",
    "positive_pairs, negative_pairs = generate_pairs(recipes_df, embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def contrastive_loss(y_true, y_pred, margin=1.0):\n",
    "    positive_loss = y_true * tf.square(y_pred)\n",
    "    negative_loss = (1 - y_true) * tf.square(tf.maximum(margin - y_pred, 0))\n",
    "    return tf.reduce_mean(positive_loss + negative_loss)\n",
    "\n",
    "input_shape = (768,)  \n",
    "input_a = layers.Input(shape=input_shape)\n",
    "input_b = layers.Input(shape=input_shape)\n",
    "\n",
    "shared_network = tf.keras.Sequential([\n",
    "    layers.InputLayer(shape=(768,)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu')\n",
    "])\n",
    "processed_a = shared_network(input_a)\n",
    "processed_b = shared_network(input_b)\n",
    "distance = layers.Lambda(lambda embeddings: tf.norm(embeddings[0] - embeddings[1], axis=1, keepdims=True))([processed_a, processed_b])\n",
    "siamese_model = Model(inputs=[input_a, input_b], outputs=distance)\n",
    "siamese_model.compile(optimizer='adam', loss=contrastive_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.fit([positive_pairs[:, 0], positive_pairs[:, 1]], np.ones(len(positive_pairs)),\n",
    "                  epochs=10, batch_size=32)\n",
    "\n",
    "siamese_model.fit([negative_pairs[:, 0], negative_pairs[:, 1]], np.zeros(len(negative_pairs)),\n",
    "                  epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar(liked_recipe_indices, top_n=5):\n",
    "    liked_embeddings = [shared_network.predict(tf.reshape(embeddings[idx], (1, -1))) for idx in liked_recipe_indices]\n",
    "    average_embedding = np.mean(np.array(liked_embeddings), axis=0)  \n",
    "    all_embeddings = shared_network.predict(embeddings)\n",
    "    similarities = cosine_similarity(average_embedding, all_embeddings)[0]\n",
    "    similar_indices = similarities.argsort()[-top_n:][::-1]  # tanpa original embedding\n",
    "\n",
    "    print(\"Liked Recipes:\")\n",
    "    liked_recipes = recipes_df.iloc[liked_recipe_indices]\n",
    "    print(liked_recipes[['title', 'categories', 'ingredients']])\n",
    "    print(\"\\nRecommended Recipes:\")\n",
    "    \n",
    "    recommended_recipes = recipes_df.iloc[similar_indices]\n",
    "    return recommended_recipes[['title', 'categories', 'ingredients']]\n",
    "\n",
    "liked_recipe_indices = [7, 20, 50]  # contoh sample list resep\n",
    "recommended_recipes = recommend_similar(liked_recipe_indices, top_n=5)\n",
    "print(recommended_recipes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
